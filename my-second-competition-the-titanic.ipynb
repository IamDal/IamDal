{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Created by: Dalton R. Burton**\n\n**Project: Kaggle Competion**\n\n**Date: 23/09/2023**","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-22T10:51:18.862187Z","iopub.execute_input":"2023-09-22T10:51:18.862652Z","iopub.status.idle":"2023-09-22T10:51:18.873858Z","shell.execute_reply.started":"2023-09-22T10:51:18.862561Z","shell.execute_reply":"2023-09-22T10:51:18.872861Z"}}},{"cell_type":"markdown","source":"# <center> Titanic - Machine Learning from Disaster<center/>\n\n#### <p><center> by: Dalton R. Burton <center/><p/>\n    \n***","metadata":{}},{"cell_type":"markdown","source":"#### The goal of this notebook is to use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\n\n## The Challenge\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: “what sorts of people were more likely to survive?” using passenger data (ie name, age, gender, socio-economic class, etc).\n\n***","metadata":{}},{"cell_type":"markdown","source":"## The Question\n\nOur target question is: \n***\n### “What sorts of people were more likely to survive?\"\n***\nIn order to determine this we must analyze passenger data and determine the right features for survival.\n\nLet's get started!\n\n***","metadata":{}},{"cell_type":"markdown","source":"# Library Imports\n***","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt # data visualization library\nimport plotly.express as px\n%matplotlib inline\nimport seaborn as sns\nfrom IPython.display import display_html\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport warnings\nwarnings.filterwarnings('ignore')\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2023-09-25T18:55:24.405186Z","iopub.execute_input":"2023-09-25T18:55:24.406751Z","iopub.status.idle":"2023-09-25T18:55:24.434086Z","shell.execute_reply.started":"2023-09-25T18:55:24.406706Z","shell.execute_reply":"2023-09-25T18:55:24.432773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n# Set styles\nLet's set the style of the notebook.\n***","metadata":{}},{"cell_type":"code","source":"# Adjusting plot style\nrc = {\n    \"axes.facecolor\": \"#F0F5F6\",\n    \"figure.facecolor\": \"#F0F5F6\",\n    \"axes.edgecolor\": \"#000000\",\n    \"grid.color\": \"#EBEBE7\" + \"30\",\n    \"font.family\": \"sans-serif\",\n    \"axes.labelcolor\": \"#000000\",\n    \"xtick.color\": \"#000000\",\n    \"ytick.color\": \"#000000\",\n    \"grid.alpha\": 0.4,\n    \"ytick.labelsize\": 8,\n    \"xtick.labelsize\": 8,\n    \"legend.title_fontsize\": 8,\n    \"legend.fontsize\": 7\n}\n\nsns.set(rc=rc)\npalette = ['#302c36', '#037d97', '#E4591E', '#C09741',\n           '#EC5B6D', '#90A6B1', '#6ca957', '#D8E3E2']\n\nfrom colorama import Style, Fore\nblk = Style.BRIGHT + Fore.BLACK\nmgt = Style.BRIGHT + Fore.MAGENTA\nred = Style.BRIGHT + Fore.RED\nblu = Style.BRIGHT + Fore.BLUE\nres = Style.RESET_ALL\n\ndef set_alternate_colors(df):\n    return [\n        'background-color: #ABDBD5' if i % 2 == 0 else 'background-color: #f2f2f2'\n        for i in range(len(df))\n    ]\n\ndef dstyle(df):\n    styled_df = df.style.apply(set_alternate_colors)\n    display_html(styled_df._repr_html_(), raw=True)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-25T18:55:28.474779Z","iopub.execute_input":"2023-09-25T18:55:28.475176Z","iopub.status.idle":"2023-09-25T18:55:28.488055Z","shell.execute_reply.started":"2023-09-25T18:55:28.475143Z","shell.execute_reply":"2023-09-25T18:55:28.486556Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n# Functions\nInitiate functions used for analyzing and machine learning\n***","metadata":{}},{"cell_type":"code","source":"def confirm(a):\n    name = a.__name__\n    print(name+ \" function has been initialized!\")\n    \n\n# --------------------------------------------------------------------------------\n# Returns a summary of data\ndef summary(df):\n    summ = pd.DataFrame(df.dtypes, columns=['dtypes'])\n    summ['missing#'] = df.isna().sum()\n    summ['missing%'] = (df.isna().sum())/len(df)\n    summ['uniques'] = df.nunique().values\n    summ['count'] = df.count().values\n    confirm(summary)\n    return summ\n\n\n# --------------------------------------------------------------------------------\n# Returns a series of countplots to compare categorical data\ndef cat_count_compare(data):\n    fig, axes = plt.subplots(1,data.shape[1],figsize = (16, 3),sharey=False)\n    for i in range(len(data.columns)):\n        ax = axes[i]\n        ax.grid(visible=True, which = 'both', linestyle = '--', color='lightgrey', linewidth = 0.75)\n        sns.countplot(x=data.columns[i],data = data, width = .4,ax = ax)\n        ax.set(xlabel = '', ylabel = '')\n        ax.set_title(data.columns[i],fontsize = 8)\n    confirm(cat_count_compare)\n    plt.show()\n    \n\n# --------------------------------------------------------------------------------\n# Returns a series of KDEplots\ndef kde_plot(data1, data2):\n    if isinstance(data1, np.ndarray):\n        if data1.shape:\n            X = pd.DataFrame(data1)\n            kde_plot_execute(X, data2)\n    if isinstance(data2, np.ndarray):\n        if data2.shape:\n            Y = pd.DataFrame(data2)\n            kde_plot_execute(data1, Y)\n    else:\n        kde_plot_execute(data1, data2)\n\n\n# --------------------------------------------------------------------------------\ndef kde_plot_execute(data1, data2):\n    width_ratios = [1] * data2.shape[1]  # Initialize with equal width\n    total_width = sum(width_ratios)\n    width_ratios = [width / total_width for width in width_ratios]\n\n    fig, axes = plt.subplots(data1.shape[1],data2.shape[1],figsize = (16, 8),sharey=False,\\\n                gridspec_kw = {'hspace': 0.35, 'wspace': 0.3,'width_ratios': width_ratios})\n    if data1.shape[1] and data1.shape[1] == 1:\n        for i,col in enumerate(data1):\n            for j,col2 in enumerate(data2):\n                ax = axes\n                ax.grid(visible=True, which = 'both', linestyle = '--', color='lightgrey', linewidth = 0.75)\n                sns.kdeplot(data = data1, x= data1[col],hue = data2[col2],palette=palette[0:8], shade=True,ax = ax)\n                ax.set_title(col + ' by '+ col2 +' Comparison',fontsize = 8)\n                ax.set(xlabel = '', ylabel = '')\n    else:\n        for i,col in enumerate(data1):\n            for j,col2 in enumerate(data2):\n                ax = axes[i,j]\n                ax.grid(visible=True, which = 'both', linestyle = '--', color='lightgrey', linewidth = 0.75)\n                sns.kdeplot(data = data1, x= data1[col],hue = data2[col2],palette=palette[0:8], shade=True,ax = ax)\n                ax.set_title(col + ' by '+ col2 +' Comparison',fontsize = 8)\n                ax.set(xlabel = '', ylabel = '')\n    confirm(kde_plot)\n        # Show the plot\n    plt.show()\n    \n\n# --------------------------------------------------------------------------------\n# Gets the summary for a Cabin\ndef cabin_summary(a):\n    deck_x = cabin_data.loc[cabin_data['New_Cabin_data'] == a]\n    return [deck_x.describe(),deck_x]\n\n\n# --------------------------------------------------------------------------------\ndef val_summary(data):\n    summ = data.describe().T\\\n    .style.bar(subset=['mean'], color=px.colors.qualitative.G10[1])\\\n    .background_gradient(subset=['std'], cmap='Reds')\\\n    .background_gradient(subset=['50%'], cmap='Reds')\n    return summ\n\n\n# --------------------------------------------------------------------------------\n# define functions to fill missing values with mode or mean\ndef nan_to_mode(df_col):\n    mode = df_col.mode()[0]\n    df_col.fillna(mode, inplace = True)\n    return df_col\n\n\n# --------------------------------------------------------------------------------\ndef nan_to_mean(df_col):\n    mean = df_col.mean()\n    df_col.fillna(mean, inplace = True)\n    return df_col\n\n\n# --------------------------------------------------------------------------------\n# defines distribution plot function\ndef DistributionPlot(RedFunction, BlueFunction, RedName, BlueName, Title):\n    width = 3\n    height = 3\n    plt.figure(figsize=(width, height))\n    \n    ax1 = sns.kdeplot(RedFunction, color='blue', label=RedName)\n    ax2 = sns.kdeplot(BlueFunction, color='green', label=BlueName, ax=ax1)\n\n    plt.title(Title)\n    plt.xlabel('X')\n    plt.ylabel('Y')\n    plt.show()\n    plt.close()\n\n\n# --------------------------------------------------------------------------------\n# best pr value and R2    \ndef best_score(model_list,order_list,xtrain,xtest,ytrain,ytest):\n    for i in range(len(model_list)):\n        Rsqu_test = []\n        for n in order:\n            pr = PolynomialFeatures(degree=n)\n            X_train_pr = pr.fit_transform(xtrain)\n            X_test_pr = pr.fit_transform(xtest)    \n            model_list[i].fit(X_train_pr, ytrain)\n\n            #train_score = model_list[i].score(X_train_pr, ytrain)\n            Rsqu_test.append(model_list[i].score(X_test_pr, ytest))\n            #Rsqu_test.append(model_list[i].score(X_train_pr, ytrain))\n        print(\"Max Score: \",model_list[i].named_steps['model'], max(Rsqu_test),\"Max Order: \",order_list[Rsqu_test.index(max(Rsqu_test))]) \n        plt.plot(order, Rsqu_test)\n        plt.xlabel('order')\n        plt.ylabel('R^2')\n        plt.title('R^2 Using Test Data')\n        \n        \n# --------------------------------------------------------------------------------        \n# Let's take a quick look at the data\ndef side_by_side(dtr,dte):\n    a = summary(dtr)\n    b = summary(dte)\n    test_col = 'Test_'\n\n    new_names = [test_col + col for col in b.columns]\n    b.columns = new_names\n\n    new_df = pd.concat([a,b],axis = 1)\n    return new_df","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-25T18:55:29.459399Z","iopub.execute_input":"2023-09-25T18:55:29.459800Z","iopub.status.idle":"2023-09-25T18:55:29.499024Z","shell.execute_reply.started":"2023-09-25T18:55:29.459769Z","shell.execute_reply":"2023-09-25T18:55:29.497652Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n# Import Machine Learning Models\nWe will load the libraries for model learning and testing.\n***","metadata":{}},{"cell_type":"code","source":"# Machine learning models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# data processing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import PolynomialFeatures\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\n\nfrom sklearn.pipeline import Pipeline","metadata":{"execution":{"iopub.status.busy":"2023-09-25T18:55:30.559017Z","iopub.execute_input":"2023-09-25T18:55:30.559457Z","iopub.status.idle":"2023-09-25T18:55:30.568716Z","shell.execute_reply.started":"2023-09-25T18:55:30.559421Z","shell.execute_reply":"2023-09-25T18:55:30.567305Z"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n# Data Wrangling\nWe will load the train and test data.\n***","metadata":{}},{"cell_type":"code","source":"# Use pandas read_csv to load csv into notebook\ntrain_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n\n# Use pandas read_csv to load csv into notebook\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n\n# prints the first 5 rows of the data\ndstyle(train_data.head())","metadata":{"execution":{"iopub.status.busy":"2023-09-25T18:55:31.392993Z","iopub.execute_input":"2023-09-25T18:55:31.393421Z","iopub.status.idle":"2023-09-25T18:55:31.422534Z","shell.execute_reply.started":"2023-09-25T18:55:31.393388Z","shell.execute_reply":"2023-09-25T18:55:31.421336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prints the first 5 rows of the test data\ndstyle(test_data.head())","metadata":{"execution":{"iopub.status.busy":"2023-09-25T18:55:31.863509Z","iopub.execute_input":"2023-09-25T18:55:31.863932Z","iopub.status.idle":"2023-09-25T18:55:31.880484Z","shell.execute_reply.started":"2023-09-25T18:55:31.863896Z","shell.execute_reply":"2023-09-25T18:55:31.879317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.drop(['Name','PassengerId','Ticket'],axis=1,inplace=True)\ntest_data.drop(['Name','PassengerId','Ticket'],axis=1,inplace=True)\n\n# prints the first 5 rows of the data\ndstyle(train_data.head())","metadata":{"execution":{"iopub.status.busy":"2023-09-25T18:55:33.496383Z","iopub.execute_input":"2023-09-25T18:55:33.496792Z","iopub.status.idle":"2023-09-25T18:55:33.513256Z","shell.execute_reply.started":"2023-09-25T18:55:33.496760Z","shell.execute_reply":"2023-09-25T18:55:33.512163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prints the first 5 rows of the test data\ndstyle(test_data.head())","metadata":{"execution":{"iopub.status.busy":"2023-09-25T18:55:34.140216Z","iopub.execute_input":"2023-09-25T18:55:34.140667Z","iopub.status.idle":"2023-09-25T18:55:34.155243Z","shell.execute_reply.started":"2023-09-25T18:55:34.140635Z","shell.execute_reply":"2023-09-25T18:55:34.153924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary_1 = side_by_side(train_data,test_data)\nsummary_1.style.background_gradient(cmap='Reds')","metadata":{"execution":{"iopub.status.busy":"2023-09-25T18:55:37.131429Z","iopub.execute_input":"2023-09-25T18:55:37.131846Z","iopub.status.idle":"2023-09-25T18:55:37.189491Z","shell.execute_reply.started":"2023-09-25T18:55:37.131813Z","shell.execute_reply":"2023-09-25T18:55:37.188309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Observations:\n\n1. At a glance, we see that 'Cabin' and 'Age' are missing a lot of data.\n2. `Survived`, `Pclass`, `Sex`, `Embarked` stand out as Categorical data.\n3. We can drop `PassengerID` and `Name` .\n4. `SibSP`,`Parch`,`Age`and`Fare` stand out as Quantitative data.\n***","metadata":{}},{"cell_type":"markdown","source":"### Replace missing values","metadata":{}},{"cell_type":"code","source":"# Let's replace missing values with the mode or average values in each set\nnan_to_mode(train_data.Embarked)\n\nnan_to_mean(test_data.Fare)\n\nnan_to_mean(train_data.Age)\nnan_to_mean(test_data.Age)\n\ntrain_data.Cabin.fillna(0, inplace = True)\ntest_data.Cabin.fillna(0, inplace = True)\n\nprint(\"Missing values replaced successfully!\")","metadata":{"execution":{"iopub.status.busy":"2023-09-25T18:55:41.624906Z","iopub.execute_input":"2023-09-25T18:55:41.625342Z","iopub.status.idle":"2023-09-25T18:55:41.638454Z","shell.execute_reply.started":"2023-09-25T18:55:41.625300Z","shell.execute_reply":"2023-09-25T18:55:41.637562Z"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Map categorial data to integers","metadata":{}},{"cell_type":"code","source":"sex_mapping = {'male': 0, 'female': 1}\nembarked_mapping = {'S': 0, 'C': 1, 'Q': 2}\nPclass_mapping = {1: 2, 2: 1, 3: 0}\n\ntest_data['Pclass'] = test_data['Pclass'].replace(Pclass_mapping)\ntrain_data['Pclass'] = train_data['Pclass'].replace(Pclass_mapping)\n\ntrain_data['Sex'] = train_data['Sex'].replace(sex_mapping)\ntest_data['Sex'] = test_data['Sex'].replace(sex_mapping)\n\ntrain_data['Embarked'] = train_data['Embarked'].replace(embarked_mapping)\ntest_data['Embarked'] = train_data['Embarked'].replace(embarked_mapping)\n\nfor x in range(len(train_data.Cabin)):\n    if train_data.Cabin[x] != 0:\n        train_data.Cabin[x] = 1\ntrain_data['Cabin'] = train_data['Cabin'].astype(int)       \nfor x in range(len(test_data.Cabin)):\n    if test_data.Cabin[x] != 0:\n        test_data.Cabin[x] = 1\ntest_data['Cabin'] = test_data['Cabin'].astype(int)        \nprint(\"Values replaced successfully!\")","metadata":{"execution":{"iopub.status.busy":"2023-09-25T18:55:42.190362Z","iopub.execute_input":"2023-09-25T18:55:42.190776Z","iopub.status.idle":"2023-09-25T18:55:42.339371Z","shell.execute_reply.started":"2023-09-25T18:55:42.190746Z","shell.execute_reply":"2023-09-25T18:55:42.338221Z"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary2 = side_by_side(train_data,test_data)\nsummary2.style.background_gradient(cmap='Reds')","metadata":{"execution":{"iopub.status.busy":"2023-09-25T18:55:42.684602Z","iopub.execute_input":"2023-09-25T18:55:42.685006Z","iopub.status.idle":"2023-09-25T18:55:42.738057Z","shell.execute_reply.started":"2023-09-25T18:55:42.684973Z","shell.execute_reply":"2023-09-25T18:55:42.736709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n# Exploratory Data Analysis\nIn this section we will take a look at the data, it's structure and try to identify patterns or irregularities.\n***","metadata":{}},{"cell_type":"markdown","source":"### Numerical Data\nLet's try to analyze the behavior of the numerical data.\n***","metadata":{}},{"cell_type":"code","source":"num_data = train_data[['Fare','Age','SibSp','Parch']]\n# Lets summarize the remainding columns\nval_summary(num_data)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T18:55:53.516098Z","iopub.execute_input":"2023-09-25T18:55:53.517540Z","iopub.status.idle":"2023-09-25T18:55:53.554974Z","shell.execute_reply.started":"2023-09-25T18:55:53.517495Z","shell.execute_reply":"2023-09-25T18:55:53.553725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, len(num_data.columns) * 2.5))\n\nfor idx, column in enumerate(num_data):\n    count, bins = np.histogram(train_data[column])\n    plt.subplot(len(num_data.columns), 2, idx*2+1)\n    sns.histplot(x=column, hue=\"Survived\", data=train_data, bins=bins, kde=True)\n    plt.title(f\"{column} Distribution for Population\",fontsize=10)\n    plt.ylim(0, train_data[column].value_counts().max() + 10)\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T18:55:57.020125Z","iopub.execute_input":"2023-09-25T18:55:57.021577Z","iopub.status.idle":"2023-09-25T18:55:59.144118Z","shell.execute_reply.started":"2023-09-25T18:55:57.021526Z","shell.execute_reply":"2023-09-25T18:55:59.142868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's see categorical data\n# First we remove the numerical data\ncat_data = train_data.drop(num_data.columns,axis=1)\nkde_plot(num_data[['Age','Fare']], cat_data)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T18:56:02.698293Z","iopub.execute_input":"2023-09-25T18:56:02.698744Z","iopub.status.idle":"2023-09-25T18:56:06.090983Z","shell.execute_reply.started":"2023-09-25T18:56:02.698707Z","shell.execute_reply":"2023-09-25T18:56:06.089679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.corr()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T18:56:14.339216Z","iopub.execute_input":"2023-09-25T18:56:14.340445Z","iopub.status.idle":"2023-09-25T18:56:14.362063Z","shell.execute_reply.started":"2023-09-25T18:56:14.340401Z","shell.execute_reply":"2023-09-25T18:56:14.360790Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_matrix = train_data.corr()\nmask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n\nplt.figure(figsize=(5, 5))\nsns.heatmap(corr_matrix, mask=mask, annot=False, cmap='YlOrBr', fmt='.2f', linewidths=4, square=True, annot_kws={\"size\": 8} )\nplt.title('Correlation Matrix', fontsize=10)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T18:56:25.232500Z","iopub.execute_input":"2023-09-25T18:56:25.232941Z","iopub.status.idle":"2023-09-25T18:56:25.740595Z","shell.execute_reply.started":"2023-09-25T18:56:25.232904Z","shell.execute_reply":"2023-09-25T18:56:25.739356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_matrix = train_data.corr()['Survived'].sort_values().to_frame()\nmask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n\nplt.figure(figsize=(5, 5))\nsns.heatmap(corr_matrix, mask=mask, annot=False, cmap='YlOrBr', fmt='.2f', linewidths=4, square=True, annot_kws={\"size\": 8} )\nplt.title('Correlation Matrix', fontsize=10)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T18:56:37.898311Z","iopub.execute_input":"2023-09-25T18:56:37.898795Z","iopub.status.idle":"2023-09-25T18:56:38.282637Z","shell.execute_reply.started":"2023-09-25T18:56:37.898756Z","shell.execute_reply":"2023-09-25T18:56:38.281381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training the model","metadata":{}},{"cell_type":"code","source":"m_features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\",\"Embarked\",\"Cabin\",\"Fare\"]\n\nX_dta = train_data[m_features]\ny_dta = train_data['Survived']\n\nX_train, X_test, y_train, y_test = train_test_split(X_dta, y_dta, test_size=.35, random_state=15)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T18:56:47.651771Z","iopub.execute_input":"2023-09-25T18:56:47.652936Z","iopub.status.idle":"2023-09-25T18:56:47.662742Z","shell.execute_reply.started":"2023-09-25T18:56:47.652895Z","shell.execute_reply":"2023-09-25T18:56:47.661552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Determine Hyperparameters\n\nWe will use 3 models, RandomForestClassifier, LogisticRegression and KNeighborsClassifier","metadata":{}},{"cell_type":"code","source":"m_models = [RandomForestClassifier(n_estimators=100), LogisticRegression(random_state = 15), KNeighborsClassifier(n_neighbors=2)]\n\nparam_grid_R = {'n_estimators': [100,200,300,400], 'max_depth': [None, 4, 8,12,14]}\nparam_grid_L = {'C': [0.001, 0.01, 0.1, 1, 10], 'penalty': ['l1', 'l2']}\nparam_grid_k = param_grid = {'n_neighbors': [3, 5, 7,9],'weights': ['uniform', 'distance'],'p': [1, 2], 'leaf_size':[2,4,6,8]}\nparam = [param_grid_R,param_grid_L,param_grid_k]","metadata":{"execution":{"iopub.status.busy":"2023-09-25T18:56:59.657372Z","iopub.execute_input":"2023-09-25T18:56:59.657779Z","iopub.status.idle":"2023-09-25T18:56:59.666533Z","shell.execute_reply.started":"2023-09-25T18:56:59.657738Z","shell.execute_reply":"2023-09-25T18:56:59.665270Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_list = []\nfor i in range(len(m_models)):\n    grid_search = GridSearchCV(estimator=m_models[i], param_grid=param[i], scoring='accuracy', cv=5)\n    grid_search.fit(X_train, y_train)\n    grid_list.append(grid_search)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T18:57:04.613404Z","iopub.execute_input":"2023-09-25T18:57:04.613802Z","iopub.status.idle":"2023-09-25T18:58:13.876729Z","shell.execute_reply.started":"2023-09-25T18:57:04.613769Z","shell.execute_reply":"2023-09-25T18:58:13.875632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_models=[]\nfor i in range(len(grid_list)):\n    best_params = grid_list[i].best_params_\n    best_models.append(grid_list[i].best_estimator_)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T18:58:13.879319Z","iopub.execute_input":"2023-09-25T18:58:13.879761Z","iopub.status.idle":"2023-09-25T18:58:13.886153Z","shell.execute_reply.started":"2023-09-25T18:58:13.879720Z","shell.execute_reply":"2023-09-25T18:58:13.884984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(best_models)):\n    scores = cross_val_score(best_models[i], X_train, y_train, cv=5, scoring='accuracy')\n    print(\"Cross-validated Accuracy:\", scores.mean())","metadata":{"execution":{"iopub.status.busy":"2023-09-25T18:58:13.887881Z","iopub.execute_input":"2023-09-25T18:58:13.888514Z","iopub.status.idle":"2023-09-25T18:58:18.904630Z","shell.execute_reply.started":"2023-09-25T18:58:13.888472Z","shell.execute_reply":"2023-09-25T18:58:18.903774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_input=[('scale',StandardScaler()), ('model',best_models[0])]\nlre_input=[('scale',StandardScaler()), ('model',best_models[1])]\nkn_input=[('scale',StandardScaler()), ('model',best_models[2])]\n\nlre = Pipeline(lre_input)\nrf = Pipeline(rf_input)\nkn = Pipeline(kn_input)\n\nmodels = [lre, rf, kn]","metadata":{"execution":{"iopub.status.busy":"2023-09-25T19:00:30.222204Z","iopub.execute_input":"2023-09-25T19:00:30.222697Z","iopub.status.idle":"2023-09-25T19:00:30.241493Z","shell.execute_reply.started":"2023-09-25T19:00:30.222663Z","shell.execute_reply":"2023-09-25T19:00:30.239848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pred_plot(Xtr, Ytr, i):\n    P = models[i].predict(Xtr)\n    accuracy = models[i].score(Xtr, Ytr)\n    title = 'Distribution plot'\n    DistributionPlot(Ytr,P,'Actual','Predicted',title)\n    print(\"Train Accuracy:\", accuracy,'i val: ',i) \n\ndef pred_plot2(Xtr, Ytr, ml):\n    P = ml.predict(Xtr)\n    accuracy = ml.score(Xtr, Ytr)\n    title = 'Distribution plot'\n    DistributionPlot(Ytr,P,'Actual','Predicted',title)\n    print(\"Train Accuracy:\", accuracy) ","metadata":{"execution":{"iopub.status.busy":"2023-09-25T19:00:33.945357Z","iopub.execute_input":"2023-09-25T19:00:33.946045Z","iopub.status.idle":"2023-09-25T19:00:33.954611Z","shell.execute_reply.started":"2023-09-25T19:00:33.946011Z","shell.execute_reply":"2023-09-25T19:00:33.953380Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m_features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\",\"Embarked\",\"Cabin\",\"Fare\"]\n\nX_dta = train_data[m_features]\ny_dta = train_data['Survived']\n\nX_train, X_test, y_train, y_test = train_test_split(X_dta, y_dta, test_size=.35, random_state=15)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T19:00:40.598203Z","iopub.execute_input":"2023-09-25T19:00:40.599235Z","iopub.status.idle":"2023-09-25T19:00:40.610927Z","shell.execute_reply.started":"2023-09-25T19:00:40.599187Z","shell.execute_reply":"2023-09-25T19:00:40.609243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#order = [2,6,10,14,18]\n# Function takes a list of models, a list of order = models,orders, xtrain,xtest,ytrain,ytest\n#best_score(models,order,X_train,X_test,y_train,y_test)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T19:00:49.441259Z","iopub.execute_input":"2023-09-25T19:00:49.441725Z","iopub.status.idle":"2023-09-25T19:04:16.757295Z","shell.execute_reply.started":"2023-09-25T19:00:49.441688Z","shell.execute_reply":"2023-09-25T19:04:16.756041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Normalizing the values of the training and test set\n#X = (X - X.mean())/X.std()\n#X_test = (X_test - X_test.mean())/X_test.std()\n\n#model = RandomForestClassifier(n_estimators=100, max_depth = 4, random_state = 0)\n#model.fit(X, y)\n#predictions = model.predict(X_test)\n\n#output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n#output.to_csv('submission.csv', index = False)\n#print(\"Your submission was successfully saved!\")","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-09-25T18:31:47.240419Z","iopub.execute_input":"2023-09-25T18:31:47.240801Z","iopub.status.idle":"2023-09-25T18:31:47.248263Z","shell.execute_reply.started":"2023-09-25T18:31:47.240768Z","shell.execute_reply":"2023-09-25T18:31:47.247351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Rlist = []\nindex1 = []\nfor i in range (2,10):\n    Rcross = cross_val_score(lre, X_test, y_test, cv=i)\n    Rlist.append(Rcross.mean())\n    index1.append(i)\nprint(\"The mean of the folds are\", max(Rlist))\nprint(\"The best val\", index1[Rlist.index(max(Rlist))])\nbest_val = index1[Rlist.index(max(Rlist))]","metadata":{"execution":{"iopub.status.busy":"2023-09-25T19:09:30.854797Z","iopub.execute_input":"2023-09-25T19:09:30.855346Z","iopub.status.idle":"2023-09-25T19:09:31.369724Z","shell.execute_reply.started":"2023-09-25T19:09:30.855306Z","shell.execute_reply":"2023-09-25T19:09:31.368359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pr = PolynomialFeatures(degree=2)\nX_train_pr = pr.fit_transform(X_train)\nX_test_pr = pr.fit_transform(X_test)\nlre.fit(X_train, y_train)\n\npred_plot2(X_train, y_train, lre)\npred_plot2(X_test, y_test, lre)\n\nlre.fit(X_train_pr, y_train)\npred_plot2(X_train_pr, y_train, lre)\npred_plot2(X_test_pr, y_test, lre)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T19:09:37.412621Z","iopub.execute_input":"2023-09-25T19:09:37.413041Z","iopub.status.idle":"2023-09-25T19:09:39.115623Z","shell.execute_reply.started":"2023-09-25T19:09:37.413008Z","shell.execute_reply":"2023-09-25T19:09:39.114762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Model on Full Data","metadata":{}},{"cell_type":"code","source":"X_dta_tr = train_data[m_features]\nX_dta_te = test_data[m_features]\ny_dta_tr = train_data['Survived']","metadata":{"execution":{"iopub.status.busy":"2023-09-25T19:10:09.040707Z","iopub.execute_input":"2023-09-25T19:10:09.041160Z","iopub.status.idle":"2023-09-25T19:10:09.051508Z","shell.execute_reply.started":"2023-09-25T19:10:09.041126Z","shell.execute_reply":"2023-09-25T19:10:09.050223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pr = PolynomialFeatures(degree=2)\nX_train_pr1 = pr.fit_transform(X_dta_tr)\nX_test_pr1 = pr.fit_transform(X_dta_te)\n\nlre.fit(X_dta_tr, y_dta_tr)\npred_plot2(X_dta_tr, y_dta_tr, lre)\n#pred_plot2(X_dta_te, y_dta_te, rf)\n\nlre.fit(X_train_pr1, y_dta_tr)\npred_plot2(X_train_pr1, y_dta_tr, lre)\n#pred_plot2(X_test_pr1, y_dta_te, rf)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T19:10:12.269817Z","iopub.execute_input":"2023-09-25T19:10:12.270265Z","iopub.status.idle":"2023-09-25T19:10:13.075234Z","shell.execute_reply.started":"2023-09-25T19:10:12.270229Z","shell.execute_reply":"2023-09-25T19:10:13.073905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = lre.predict(X_test_pr1)\ntest_data2 = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\noutput = pd.DataFrame({'PassengerId': test_data2.PassengerId, 'Survived': predictions})\noutput.to_csv('submission.csv', index = False)\nprint(\"Your submission was successfully saved!\")","metadata":{"execution":{"iopub.status.busy":"2023-09-25T19:10:33.023916Z","iopub.execute_input":"2023-09-25T19:10:33.024657Z","iopub.status.idle":"2023-09-25T19:10:33.067156Z","shell.execute_reply.started":"2023-09-25T19:10:33.024618Z","shell.execute_reply":"2023-09-25T19:10:33.065059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data2 = pd.concat([test_data2,output['Survived']],join='outer',axis=1)\ntest_data2['Age'] = test_data['Age']\ntest_data2.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T19:10:37.867864Z","iopub.execute_input":"2023-09-25T19:10:37.868264Z","iopub.status.idle":"2023-09-25T19:10:37.890005Z","shell.execute_reply.started":"2023-09-25T19:10:37.868226Z","shell.execute_reply":"2023-09-25T19:10:37.888621Z"},"_kg_hide-output":true,"_kg_hide-input":true,"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data2 = pd.concat([test_data2,output['Survived']],join='outer',axis=1)\ntest_data2['Age'] = test_data['Age']\ntest_data2.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T19:17:43.109131Z","iopub.execute_input":"2023-09-25T19:17:43.110684Z","iopub.status.idle":"2023-09-25T19:17:43.132809Z","shell.execute_reply.started":"2023-09-25T19:17:43.110640Z","shell.execute_reply":"2023-09-25T19:17:43.131600Z"},"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}